{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5832650146bb403",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neural search for question answering\n",
    "\n",
    "\n",
    "### Windows installation is tough\n",
    "\n",
    "In wsl:\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "sudo apt install -y software-properties-common\n",
    "sudo apt upgrade -y\n",
    "sudo add-apt-repository ppa:deadsnakes/ppa\n",
    "sudo apt update\n",
    "sudo apt install -y python3.10 python3.10-venv python3.10-distutils\n",
    "python3.10 --version\n",
    "sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
    "sudo update-alternatives --config python3\n",
    "python3 -m venv haystack_env\n",
    "source haystack_env/bin/activate\n",
    "pip install --upgrade pip\n",
    "pip install jupyter\n",
    "pip install farm-haystack[all]\n",
    "\n",
    "sudo apt install -y libpq-dev libsndfile1 ffmpeg\n",
    "\n",
    "jupyter notebook --no-browser --ip=0.0.0.0\n",
    "\n",
    "```\n",
    "\n",
    "Connect to `http://127.0.0.1:8888/?token=your_token_here`\n",
    "\n",
    "The token is displayed in the wsl command prompt window\n",
    "\n",
    "---\n",
    "\n",
    "Installing and setting up haystack on windows took most of the time spent on this laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4230f6e4-b601-4ff9-9de0-a359b9844ee7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Configure document store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-04T18:25:50.107946Z",
     "start_time": "2024-12-04T18:25:50.089706900Z"
    }
   },
   "outputs": [],
   "source": [
    "from haystack.document_stores import FAISSDocumentStore\n",
    "\n",
    "document_store = FAISSDocumentStore(\n",
    "    similarity=\"cosine\",  # the e5 models were trained with a cosine similarity function\n",
    "    embedding_dim=768,\n",
    ")\n",
    "\n",
    "# # if the index is already saved\n",
    "# document_store = FAISSDocumentStore(\n",
    "#     faiss_index_path=\"faiss_index.faiss\" ,\n",
    "# )\n",
    "\n",
    "document_store.save(\"faiss_index.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d669749-5b2f-4c3a-9dde-ade35e96b5db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load fiqa and store the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba57f9e-6cd9-4e9e-81c0-1905360d941b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "riting Documents: 60000it [00:36, 1662.71it/s]                                                                         "
     ]
    }
   ],
   "source": [
    "from haystack import Document\n",
    "from datasets import load_dataset\n",
    "\n",
    "fiqa_corpus = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")[\"corpus\"]\n",
    "fiqa_queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")[\"queries\"]\n",
    "\n",
    "documents = []\n",
    "\n",
    "for entry in fiqa_corpus:\n",
    "    idx = entry[\"_id\"]\n",
    "    text = entry[\"text\"]\n",
    "    documents.append(Document(content=text, id=idx))\n",
    "\n",
    "document_store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1768229-701b-4418-8b3f-0701d878fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiqa_qa = load_dataset(\"clarin-knext/fiqa-pl-qrels\")[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76d797-db4b-4a03-a12d-85be5073bc61",
   "metadata": {},
   "source": [
    "### Update embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05190799-a4cf-4a51-bc85-34da4f73fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import EmbeddingRetriever\n",
    "\n",
    "e5 = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"intfloat/multilingual-e5-base\",\n",
    "    model_format=\"transformers\",  # Make sure we specify the transformers model format\n",
    "    pooling_strategy=\"reduce_mean\",  # This is the pooling method used to train the e5 models\n",
    "    top_k=20,\n",
    "    max_seq_len=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcc3ed03-fd48-4d85-80fd-b4e96ee9aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "document_store.update_embeddings(e5)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "379d0f00-3954-49b7-9eb7-dcde6b6f96c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding update time: 464.18s\n"
     ]
    }
   ],
   "source": [
    "print(f\"embedding update time: {round(end-start,2)}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f5856-66f0-4fbd-95b6-ad0262608f24",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Prepare data for NDCG@k computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8cf4cdb-a394-4704-9a53-0c243d926070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create map query id -> query text\n",
    "query_map = {int(idx): q for idx, q in zip(fiqa_queries[\"_id\"], fiqa_queries[\"text\"])}\n",
    "\n",
    "# create map query id -> relevant corpus ids\n",
    "query_corpus_map = {}\n",
    "for query_id, corpus_id in zip(fiqa_qa[\"query-id\"], fiqa_qa[\"corpus-id\"]):\n",
    "    if query_id not in query_corpus_map:\n",
    "        query_corpus_map[query_id] = []\n",
    "    query_corpus_map[query_id].append(corpus_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b2894-cbe9-4aa8-abde-4d07448f5325",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### NDCG@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2122537e-0824-40bb-a96e-95bd513f7aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def ndcg_at_k(k):\n",
    "    logs = np.log2(np.arange(2, 2 + k))\n",
    "\n",
    "    # iterate over all queries to compute ndcg for each of them\n",
    "    ndcg_list = []\n",
    "\n",
    "    for query_id, corpus_id_list in query_corpus_map.items():\n",
    "        query_text = query_map[query_id]\n",
    "\n",
    "        retrieved_docs = e5.retrieve(query=query_text, top_k=k)\n",
    "\n",
    "        hits = [int(h.id) for h in retrieved_docs]\n",
    "\n",
    "        idcg = [1 if i < len(corpus_id_list) else 0 for i in range(k)]\n",
    "        dcg = [1 if h in corpus_id_list else 0 for h in hits]\n",
    "\n",
    "        idcg = np.array(idcg) / logs\n",
    "        dcg = np.array(dcg) / logs\n",
    "\n",
    "        ndcg_list.append(dcg.sum() / idcg.sum())\n",
    "\n",
    "    return np.mean(ndcg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "20b10631-d6d7-4d36-bae5-52b87be2cefe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "ndcg_at_5 = ndcg_at_k(5)\n",
    "ndcg_at_10 = ndcg_at_k(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e1b6465-6626-484d-86bb-e62ffec7cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2139199747330796"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01202b26-08de-4d46-bc69-e1eaf1331b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23300445613152695"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_at_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132af9a3-7d5e-4887-a9e2-3c93d306e7ff",
   "metadata": {},
   "source": [
    "Using FTS we got NDCG@5 around 0.18 and 0.15 for NDCG@10\n",
    "\n",
    "Using reranking we got NDCG@10 equal to around 0.05\n",
    "\n",
    "Using Neural search we managed to drastically improve the NDCG@k score in comparison to FTS achieving over 0.21 and 0.23 scores for NDCG@5 and NDCG@10 respectively\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5d548-a8dd-4fd3-8b39-a972d49fac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
