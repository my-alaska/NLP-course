{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3657b63896964595",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# NER vs LLM\n",
    "\n",
    "---\n",
    "\n",
    "### Configure OLLama\n",
    "\n",
    "Install OLLama\n",
    "\n",
    "Open terminal and type:\n",
    "\n",
    "`ollama run phi3:3.8b`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4d3081191a8c23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:15:47.667934800Z",
     "start_time": "2024-12-01T13:15:43.379968400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# This code returns an empty string...\n",
    "\n",
    "url = \"http://localhost:11434/api/chat\" \n",
    "\n",
    "question = \"Hi. Can you help me?\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"phi3:3.8b\",\n",
    "    \"message\":[{\"role\":\"user\",\"content\": question}],\n",
    "    \"stream\": False,\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "# Parse the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\\n\", response.json()[\"message\"][\"content\"])\n",
    "else:\n",
    "    print(\"Error:\\n\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53109ee9844a45c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:16:09.756389200Z",
     "start_time": "2024-12-01T13:16:07.417134600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "url = \"http://localhost:11434/api/generate\" \n",
    "\n",
    "def prompt_ollama(text):\n",
    "    payload = {\n",
    "        \"model\": \"phi3:3.8b\",\n",
    "        \"prompt\": text,\n",
    "        \"context\": [1],\n",
    "        \"options\":{\n",
    "            \"top_k\": 10,\n",
    "            \"temperature\": 0\n",
    "        },\n",
    "        \"stream\": False,\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, data=json.dumps(payload))\n",
    "    \n",
    "    # Parse the response\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"response\"]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6be02d3-0f4c-4444-85fc-85208d2bd0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Kraków', 'Polska']\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ollama(\"Identify so called named entities in this sentence: \\'Kraków jest największym miastem w Polsce\\'. After that list out the entities in a form of strings in a python list. I want your response to only include the python list without any additional code or \\\"```\\\" characters. Be careful to use the polish form of the words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3a6061ed99ee4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Take 1000 passages from fiqa corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8659417aeb1d6159",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:15:54.667513900Z",
     "start_time": "2024-12-01T13:15:50.032987600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from numpy.random import choice\n",
    "\n",
    "fiqa_corpus = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")[\"corpus\"]\n",
    "\n",
    "fiqa_corpus = fiqa_corpus[\"text\"]\n",
    "fiqa_idx = choice(len(fiqa_corpus), 100, replace=False)\n",
    "fiqa_corpus = [fiqa_corpus[i] for i in fiqa_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459d8c3dacc20f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "### NER baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb79bacc2f8db69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:16:00.510990800Z",
     "start_time": "2024-12-01T13:15:54.667513900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "def get_ents(text):\n",
    "    doc = nlp(text)\n",
    "    entity_dict = {}\n",
    "    for ent in doc.ents:\n",
    "        text, label = ent.text, ent.label_\n",
    "        if (text, label) not in entity_dict.keys():\n",
    "            entity_dict[(text, label)] = 0\n",
    "        entity_dict[(text, label)] += 1\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb224b7fb0f5fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:16:00.528696400Z",
     "start_time": "2024-12-01T13:16:00.527185400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"Named entities are real-world objects, such as a people, locations, organizations, products, etc., that can be denoted with a proper name.\\n\"\n",
    "    \"List out the named entities in the Polish text that I'm providing.\\n\"\n",
    "    \"Precise categories of named entities that you should recognize:\\n\"\n",
    "    \"- date\\n\"\n",
    "    \"- geogName\\n\"\n",
    "    \"- orgName\\n\"\n",
    "    \"- persName\\n\"\n",
    "    \"- placeName\\n\"\n",
    "    \"- time\\n\\n\"\n",
    "    \"The text is written in Polish so do not translate the entities to english.\\n\"\n",
    "    \"Use the neutral polish nominative case to list out entities\\n\"\n",
    "    \"The output should be a list of tuples consisting of named entity and it's category\\n\"\n",
    "    \"The output should look as follows:\\n\"\n",
    "    \"[('Name1', 'categoryName1'), ('Name2', 'categoryName1')] \\n\\n\"\n",
    "    \"Output the list string only. Do not add any additional characters, translation or information.\\n\"\n",
    "    \"In case of no entities found, return an empty list and nothing else.\\n\\n\"\n",
    "    \"List out the named entities in the privded text:\\n\"\n",
    ")\n",
    "\n",
    "prompt_few_shot = (\n",
    "    \"Named entities are real-world objects, such as a people, locations, organizations, products, etc., that can be denoted with a proper name.\\n\"\n",
    "    \"List out the named entities in the Polish text that I'm providing.\\n\"\n",
    "    \"Precise categories of named entities that you should recognize:\\n\"\n",
    "    \"- date\\n\"\n",
    "    \"- geogName\\n\"\n",
    "    \"- orgName\\n\"\n",
    "    \"- persName\\n\"\n",
    "    \"- placeName\\n\"\n",
    "    \"- time\\n\\n\"\n",
    "    \"The text is written in Polish so do not translate the entities to english.\\n\"\n",
    "    \"Use the neutral polish nominative case to list out entities\\n\"\n",
    "    \"The output should be a list of tuples consisting of named entity and it's category\\n\"\n",
    "    \"The output should look as follows:\\n\"\n",
    "    \"[('Name1', 'categoryName1'), ('Name2', 'categoryName1')]\\n\\n\"\n",
    "    \"Output the list string only. Do not add any additional characters, translation or information.\\n\"\n",
    "    \"In case of no entities found, return an empty list and nothing else.\\n\\n\"\n",
    "\n",
    "    \"For a given sentence 'George Washington był prezydentem Stanów Zjednoczonych' the output should be:\\n\"\n",
    "    \"[('George Washington','persName'),('Stany Zjednoczone','geogName')]\\n\"\n",
    "    \"For a given sentence 'Artur Rojek nie jest już wokalistą Myslovitz' the output should be:\\n\"\n",
    "    \"[('Artur Rojek', 'persName'),('Myslovitz', 'orgName')] \\n\\n\"\n",
    "    \n",
    "    \"List out the named entities in the privded text:\\n\"\n",
    ")\n",
    "\n",
    "example_text = \"Wczoraj w Krakowie miało miejsce spotkanie prezydentów Polski i Stanów Zjednoczonych.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb30282b-1ff5-441d-b6b5-ec7cb5041d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "# We use spacy to lemmatize if possible as the llm seems to be oblivious to the intricacy of case declension\n",
    "def get_llm_ents(text, few_shot = False):\n",
    "    p = prompt_few_shot if few_shot else prompt\n",
    "    response = prompt_ollama(p + text)\n",
    "    \n",
    "    entity_dict = {}\n",
    "    for entity, label in literal_eval(response):\n",
    "        ents_tmp = list(nlp(entity).sents)\n",
    "        if len(ents_tmp):\n",
    "            lemma = \" \".join([l.lemma_ for l in ents_tmp[0]])\n",
    "        else:\n",
    "            lemma = entity\n",
    "        if (lemma, label) not in entity_dict.keys():\n",
    "            entity_dict[(lemma, label)] = 0\n",
    "        entity_dict[(lemma, label)] += 1\n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7801ef-7f2d-439b-b00b-c9f54cfaf1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('wczoraj', 'time'): 1,\n",
       " ('Krakowie', 'placeName'): 1,\n",
       " ('prezydent', 'orgName'): 1,\n",
       " ('Polska', 'country'): 1,\n",
       " ('Stany Zjednoczone', 'orgName'): 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_llm_ents(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e7325-b82d-4a08-a2ec-1d98496830db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0943b14-2001-4aca-b3b4-467504704cd2",
   "metadata": {},
   "source": [
    "### Compare spaCy to PHI-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dabaf2a-a8f5-4bb5-961b-16ba06500e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "fiqa_spacy = [get_ents(text) for text in fiqa_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f432afc-2caa-441b-841c-b7790c8585cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[10], line 1\u001b[0m\n    fiqa_llm = [get_llm_ents(text) for text in fiqa_corpus]\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[10], line 1\u001b[0m in \u001b[0;35m<listcomp>\u001b[0m\n    fiqa_llm = [get_llm_ents(text) for text in fiqa_corpus]\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[7], line 9\u001b[0m in \u001b[0;35mget_llm_ents\u001b[0m\n    for entity, label in literal_eval(response):\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:64\u001b[0m in \u001b[0;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ast.py:50\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    [('Właściwie', 'time'), ('biegać', 'verb'), ('na biznes', 'purpose'), ('potencjalnie!', 'conjunction'), ('uśmiech', 'personName'), ('wziąć zamieszkań', 'placeName'), ('lokalna usługa „concierge”’, 'orgName')]\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "fiqa_llm = [get_llm_ents(text) for text in fiqa_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b7cd6-8bea-4549-8851-9f6eaa5204be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiqa_llm_few_shot = [get_llm_ents(text,few_shot=True) for text in tqdm(fiqa_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085470f-9af9-4ea9-9cd5-d10b954bc974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "save_path = Path(\"data\")\n",
    "save_path.mkdir(exist_ok=True,parents=True)\n",
    "\n",
    "with open(save_path / 'fiqa_spacy.pkl', 'wb') as fp:\n",
    "    pickle.dump(fiqa_spacy, fp)\n",
    "\n",
    "with open(save_path / 'fiqa_llm.pkl', 'wb') as fp:\n",
    "    pickle.dump(fiqa_llm, fp)\n",
    "\n",
    "with open(save_path / 'fiqa_llm_few_shot.pkl', 'wb') as fp:\n",
    "    pickle.dump(fiqa_llm_few_shot, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea8071-179c-41ba-9fe1-53529053eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ent_cat_count(entity_dict_list):\n",
    "    entities, categories = {}, {}\n",
    "    for d in entity_dict_list:\n",
    "        for (entity,category), count in d.items():\n",
    "            if entity not in entities.keys():\n",
    "                entities[entity] = 0\n",
    "            if category not in categories.keys():\n",
    "                categories[category] = 0\n",
    "            entities[entity] += count\n",
    "            categories[category] += count\n",
    "    entities = sorted(list(entities.items()),key=lambda x: x[1],reverse=True)\n",
    "    categories = sorted(list(categories.items()),key=lambda x: x[1],reverse=True)\n",
    "    return entities, categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4dcbaa-76d3-449a-ba0a-62b11c23c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_entities, spacy_categories = get_ent_cat_count(fiqa_spacy)\n",
    "llm_entities, llm_categories = get_ent_cat_count(fiqa_llm)\n",
    "few_shot_entities, few_shot_categories = get_ent_cat_count(fiqa_llm_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff42cd0-6bf0-4dc1-9f3d-5f86e325a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82c125-5a74-4161-882a-45403312aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af82cb6-61e7-4d29-97e8-93a121e9142c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58cc1c7-93ec-4d3e-8fa1-93488f4d9b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
