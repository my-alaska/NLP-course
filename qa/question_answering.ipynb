{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aef6e1e2e0a6a2be",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load simple-legal-questions-pl dataset\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f0d26d5f9c51f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:50:25.513573300Z",
     "start_time": "2025-01-08T20:50:24.553915Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "\n",
    "passage_dict = {}\n",
    "title_dict = {}\n",
    "with open(\"data/passages.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        d = json.loads(line)\n",
    "        passage_dict[d[\"_id\"]] = d[\"text\"]\n",
    "        title_dict[d[\"_id\"]] = d[\"title\"]\n",
    "\n",
    "question_dict = {}\n",
    "with open(\"data/questions.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        d = json.loads(line)\n",
    "        question_dict[d[\"_id\"]] = d[\"text\"]\n",
    "\n",
    "answer_dict = {}\n",
    "with open(\"data/answers.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        d = json.loads(line)\n",
    "        answer_dict[d[\"question-id\"]] = d[\"answer\"]\n",
    "\n",
    "test_dataset = {\n",
    "    \"id\": [],\n",
    "    \"title\": [],\n",
    "    \"context\": [],\n",
    "    \"question\": [],\n",
    "    \"answers\": [],\n",
    "}\n",
    "\n",
    "with open(\"data/relevant.jl\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        d = json.loads(line)\n",
    "        # test only on questions that have answers\n",
    "        if d[\"question-id\"] not in answer_dict or answer_dict[d[\"question-id\"]] == \"\":\n",
    "            continue\n",
    "        test_dataset[\"id\"].append(d[\"question-id\"])\n",
    "        test_dataset[\"title\"].append(title_dict[d[\"passage-id\"]])\n",
    "        test_dataset[\"context\"].append(passage_dict[d[\"passage-id\"]])\n",
    "        test_dataset[\"question\"].append(question_dict[d[\"question-id\"]])\n",
    "        test_dataset[\"answers\"].append(answer_dict[d[\"question-id\"]])\n",
    "\n",
    "test_dataset = Dataset.from_dict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31662f3b30b2da1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load and process PoQuAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:50:28.024094700Z",
     "start_time": "2025-01-08T20:50:25.513864Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "poquad = load_dataset(\"clarin-pl/poquad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da83fdf5a9b0b77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:50:28.030942700Z",
     "start_time": "2025-01-08T20:50:28.026432700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def load(dataset, path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    answers = []\n",
    "    for data_dict in data[\"data\"]:\n",
    "        for p in data_dict[\"paragraphs\"]:\n",
    "            for qa in p[\"qas\"]:\n",
    "                if qa[\"is_impossible\"]:\n",
    "                    continue\n",
    "                for answer in qa[\"answers\"]:\n",
    "                    answers.append(answer[\"generative_answer\"])\n",
    "\n",
    "    poquad_dataset = {\n",
    "        \"id\": dataset[\"id\"],\n",
    "        \"title\": dataset[\"title\"],\n",
    "        \"context\": dataset[\"context\"],\n",
    "        \"question\": dataset[\"question\"],\n",
    "        \"answers\": answers,\n",
    "    }\n",
    "\n",
    "    return poquad_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58ed4caab06ed2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:50:28.936808700Z",
     "start_time": "2025-01-08T20:50:28.028942700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = load(poquad[\"train\"], \"poquad-train.json\")\n",
    "train_dataset = Dataset.from_dict(train_dataset)\n",
    "\n",
    "valid_dataset = load(poquad[\"validation\"], \"poquad-dev.json\")\n",
    "valid_dataset = Dataset.from_dict(valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f37e68b5df86d0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Load and prepare plt5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992ef66a9d3e028a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T20:50:30.299109600Z",
     "start_time": "2025-01-08T20:50:28.937809200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a0522bd79a8435",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-08T20:50:30.295109100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allegro/plt5-base\")\n",
    "\n",
    "# Important class. Without that the trainer won't convert the \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allegro/plt5-base\")\n",
    "model.to(device)\n",
    "[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd291a6d144b83",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-08T20:50:30.296109500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e4008deb0b4c69a508516c922e429d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46187 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piotr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# def preprocess(examples):\n",
    "#     inputs = [f\"pytanie: {q} \\n kontekst: {c}\" for q, c in zip(examples[\"question\"], examples[\"context\"])]\n",
    "#     targets = examples[\"answers\"]\n",
    "#\n",
    "#     # model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "#     # with tokenizer.as_target_tokenizer():\n",
    "#     #     labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\").input_ids\n",
    "#\n",
    "#     model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "#     labels = tokenizer(text_target=targets, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "#\n",
    "#     # Replace padding token id for labels to ignore index (-100) in loss computation\n",
    "#     labels[\"input_ids\"] = [[l if l != tokenizer.pad_token_id else -100 for l in label] for label in labels[\"input_ids\"]]\n",
    "#\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs\n",
    "\n",
    "\n",
    "def preprocess(examples):\n",
    "    inputs = [\n",
    "        f\"pytanie: {q} \\n kontekst: {c}\"\n",
    "        for q, c in zip(examples[\"question\"], examples[\"context\"])\n",
    "    ]\n",
    "    targets = examples[\"answers\"]\n",
    "\n",
    "    # Tokenizing inputs and targets\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Tokenizing targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            targets,\n",
    "            max_length=128,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    # Replace padding token id for labels to ignore index (-100) in loss computation\n",
    "    labels[\"input_ids\"] = [\n",
    "        [l if l != tokenizer.pad_token_id else -100 for l in label]\n",
    "        for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "# Create dataset and preprocess\n",
    "\n",
    "train_dataset_preprocessed = train_dataset.map(preprocess, batched=True)\n",
    "valid_dataset_preprocessed = valid_dataset.map(preprocess, batched=True)\n",
    "test_dataset_preprocessed = test_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ad10b9731338",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-08T20:50:30.298109300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=2000,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=2000,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_preprocessed,\n",
    "    eval_dataset=valid_dataset_preprocessed,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c947ee-ddc1-47c3-b3a0-1110f89f6ec5",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb85e9c08e2c44f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-08T20:50:30.298109300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"exact_match\", \"f1\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels, _ = eval_preds\n",
    "    \n",
    "    print(\"decoding predictions\")\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    print(\"decoding labels\")\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    print(\"computing metrics\")\n",
    "    results = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    n = len(decoded_preds)\n",
    "    results[\"exact_match\"] / n * 100, results[\"f1\"] / n * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bffb1d-ce35-4849-bd20-ded888952d17",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61359116-ed2e-4829-82cd-191d08456b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset=test_dataset_preprocessed)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4506a590-04c2-49d9-b811-61632f82aa00",
   "metadata": {},
   "source": [
    "```{'eval_loss': 14.340641021728516, 'eval_model_preparation_time': 0.005, 'eval_runtime': 8.9796, 'eval_samples_per_second': 66.039, 'eval_steps_per_second': 4.232} before training```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bfed1-2c0f-46bf-9b03-34cb962e1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1028e-b404-47ee-b6f7-94c28d1827b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# This cell takes far too much time. I don't know why but it doesn't seem right\n",
    "\n",
    "start = time()\n",
    "exact_match, f1 = compute_metrics(predictions)\n",
    "end = time()\n",
    "\n",
    "print(f\"Evaluation time: {end - start} s\")\n",
    "print(f\"Exact Match:     {exact_match}\")\n",
    "print(f\"F1 Score:        f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a4680-00c6-484a-b31a-fb9506809c2f",
   "metadata": {},
   "source": [
    "### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ef089-8428-4d8a-ab28-392174a546a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset=valid_dataset_preprocessed)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcb9330-462f-4c3f-bf3f-8cea69ce45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(valid_dataset_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9924197-4c09-46ab-9ef5-cc445baa1958",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "exact_match, f1 = compute_metrics(predictions)\n",
    "end = time()\n",
    "\n",
    "print(f\"Evaluation time: {end - start} s\")\n",
    "print(f\"Exact Match:     {exact_match}\")\n",
    "print(f\"F1 Score:        f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d144a-2ae8-4771-b4dc-4c6de9cc8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset=test_dataset_preprocessed)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6cc162-724b-4633-9f9e-517b94fb6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45bef05-9083-4298-85fd-923eb1410782",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = compute_metrics(predictions)\n",
    "print(\"Exact Match:\", metrics[\"exact_match\"])\n",
    "print(\"F1 Score:\", metrics[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46f744-c48c-442d-af87-e1d6097bd6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
