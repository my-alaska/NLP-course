{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:30.276064700Z",
     "start_time": "2024-11-06T10:07:22.936879Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1, 2 - Download models\n",
    "\n",
    "Hugging Face allows for filtering models by task. Selecting `Fill-Mask` option allowed me to search for correct models.\n",
    "\n",
    "Selected models:\n",
    "- [roberta](https://huggingface.co/FacebookAI/xlm-roberta-base)\n",
    "- [distilbert](https://huggingface.co/distilbert/distilbert-base-multilingual-cased)\n",
    "- [Polish longformer](https://huggingface.co/sdadas/polish-longformer-large-4096)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a65ffec75569b27"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "roberta = pipeline(task=\"fill-mask\", model=\"FacebookAI/xlm-roberta-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:31.955915700Z",
     "start_time": "2024-11-06T10:07:30.277065100Z"
    }
   },
   "id": "d9c397391f90b8b0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "distilbert = pipeline(\n",
    "    task=\"fill-mask\", model=\"distilbert/distilbert-base-multilingual-cased\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:32.608472700Z",
     "start_time": "2024-11-06T10:07:31.948915100Z"
    }
   },
   "id": "c27d822d1318e9e6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sdadas/polish-longformer-large-4096 were not used when initializing LongformerForMaskedLM: ['longformer.embeddings.position_ids']\n",
      "- This IS expected if you are initializing LongformerForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "longformer = pipeline(task=\"fill-mask\", model=\"sdadas/polish-longformer-large-4096\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:33.428319Z",
     "start_time": "2024-11-06T10:07:32.603472500Z"
    }
   },
   "id": "2ac0e801fa6cb4fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 3 - See if model understands Polish cases"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0de2783c0fbfd60"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "cases = [\n",
    "    \"mianownik\",\n",
    "    \"dopełniacz\",\n",
    "    \"celownik\",\n",
    "    \"biernik\",\n",
    "    \"narzędnik\",\n",
    "    \"miejscownik\",\n",
    "    \"wołacz\",\n",
    "]\n",
    "\n",
    "queries_roberta = [\n",
    "    \"<mask> jest największym eksporterem wina.\",\n",
    "    \"Bez <mask> nie damy rady dokończyć projektu\",\n",
    "    \"Dałem <mask> dziś wolne. Bardzo się ucieszył.\",\n",
    "    \"Zastąpiłem dziś <mask> na nocnej zmianie.\",\n",
    "    \"Poszliśmy dziś z <mask> na plażę.\",\n",
    "    \"Polska to najciekawszy kraj w <mask>\",\n",
    "    \"Szanowny <mask>, chciałbym prosić Pana o przysługę.\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:33.428319Z",
     "start_time": "2024-11-06T10:07:33.422806800Z"
    }
   },
   "id": "69e7f4a6b4704107"
  },
  {
   "cell_type": "markdown",
   "source": [
    "roberta"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3df4573ab77874a0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mianownik : Polska\n",
      "dopełniacz : niego\n",
      "celownik : mu\n",
      "biernik : pracę\n",
      "narzędnik : dziećmi\n",
      "miejscownik : Europie\n",
      "wołacz : Pan\n"
     ]
    }
   ],
   "source": [
    "for query, case in zip(queries_roberta, cases):\n",
    "    print(f\"{case} : {roberta(query)[0]['token_str']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:34.102933Z",
     "start_time": "2024-11-06T10:07:33.425318200Z"
    }
   },
   "id": "60a14c6ffe879376"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model fails at predicting the last case - wołacz - correctly\n",
    "\n",
    "---\n",
    "\n",
    "longformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21c24023e72ab304"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mianownik : Polska\n",
      "dopełniacz : Was\n",
      "celownik : mu\n",
      "biernik : kolegę\n",
      "narzędnik : dziećmi\n",
      "miejscownik : Europie\n",
      "wołacz : Panie\n"
     ]
    }
   ],
   "source": [
    "for query, case in zip(queries_roberta, cases):\n",
    "    print(f\"{case} : {longformer(query)[0]['token_str']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:40.352075100Z",
     "start_time": "2024-11-06T10:07:34.095932900Z"
    }
   },
   "id": "38001556c6f5394c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inference with Polish longformer was visibly slower than on roberta model. Is able handle polish cases much more accurately. No mistakes were made\n",
    "\n",
    "---\n",
    "\n",
    "distilbert"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f266e434df3ca821"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mianownik : Miasto\n",
      "dopełniacz : tego\n",
      "celownik : było\n",
      "biernik : pracował\n",
      "narzędnik : преко\n",
      "miejscownik : Europie\n",
      "wołacz : ##m\n"
     ]
    }
   ],
   "source": [
    "queries_distilbert = [q.replace(\"<mask>\", \"[MASK]\") for q in queries_roberta]\n",
    "\n",
    "for query, case in zip(queries_distilbert, cases):\n",
    "    print(f\"{case} : {distilbert(query)[0]['token_str']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:40.667988900Z",
     "start_time": "2024-11-06T10:07:40.344076200Z"
    }
   },
   "id": "d495977bb9c001b0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model makes noticable errors and even failed to detect polish language in the 5th case. The 7th case looks like a complete gibberish"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2661676ad814a524"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 4 - Long-range relationships\n",
    "\n",
    "roberta"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae7d345b983ff912"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'jej'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Zaprosiła mnie do kina. Oboje jesteśmy introwertykami ale myślałem, że za jakiś czas, w końcu się przemogę i to ja zrobię pierwszy ruch. Nie spodziewałem się tego z <mask> strony.\"\n",
    "\n",
    "roberta(query)[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:40.761380700Z",
     "start_time": "2024-11-06T10:07:40.657989Z"
    }
   },
   "id": "a680b24548e0379c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model is able to recognize subject gender even in long range.\n",
    "\n",
    "---\n",
    "\n",
    "longformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "640e0fcf62d5bd2b"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'jej'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longformer(query)[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:41.464299200Z",
     "start_time": "2024-11-06T10:07:40.758381Z"
    }
   },
   "id": "5589c4c62587b086"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Result identical to roberta\n",
    "\n",
    "---\n",
    "\n",
    "distilbert"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8855ac942a4ab70"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'jednej'"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert(query.replace(\"<mask>\", \"[MASK]\"))[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:41.556925500Z",
     "start_time": "2024-11-06T10:07:41.454300Z"
    }
   },
   "id": "12b37373ecf1d065"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model uses completely incorrect word that only fits into a very local context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fba0206fd6bf79e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c50327e399bfc813"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 5 - real world knowledge\n",
    "\n",
    "roberta"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dd51cdc5f2f1c6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "'poniedziałek'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Pierwszy miesiąc w roku nazywa się <mask>.\"\n",
    "\n",
    "roberta(query)[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:41.576552500Z",
     "start_time": "2024-11-06T10:07:41.508926200Z"
    }
   },
   "id": "67b7dee1953f4d88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "longformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3780cf109e4a9655"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "'styczeń'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longformer(query)[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:42.302233700Z",
     "start_time": "2024-11-06T10:07:41.563552200Z"
    }
   },
   "id": "698dc8d958f1132d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "distilbert"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5203f37e26494401"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "'rok'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert(query.replace(\"<mask>\", \"[MASK]\"))[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:42.368187600Z",
     "start_time": "2024-11-06T10:07:42.289234400Z"
    }
   },
   "id": "ae993de083250376"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Only polish longformer was able to predict the word correctly\n",
    "\n",
    "The example below shows that the model is capable to display the needed knowledge when using English."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90209c4668709d93"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'January'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta(\"The first month of the year is called <mask>.\")[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:12:07.954599200Z",
     "start_time": "2024-11-06T10:12:07.877611600Z"
    }
   },
   "id": "fe9b6ad2e5fa80ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "distilbert performs poorly..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cd1c74981731af"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'Ґ'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert(\"The first month of the year is called [MASK].\")[0][\"token_str\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:20:37.069369200Z",
     "start_time": "2024-11-06T10:20:37.037172900Z"
    }
   },
   "id": "c96eb53444752830"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "879550249ccb0468"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 6 - zero-shot learning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "373d6b38880a3b8a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "queries_roberta = [\n",
    "    \"Analizując emocje w tekście 'Ten film był niesamowity. Naprawdę świetnie się bawiłem' możemy stwierdzić, że wypowiedź ta ma <mask> charakter\",\n",
    "    \"Analizując emocje w tekście 'Ten film był okropny. Myślałem, że wyjdę w połowie' możemy stwierdzić, że wypowiedź ta ma <mask> charakter\",\n",
    "    \"Analizując emocje w tekście 'Ten film był niezły. Myślę, że godny polecenia' możemy stwierdzić, że wypowiedź ta ma <mask> charakter\",\n",
    "    \"Analizując emocje w tekście 'Ten film był straszny. Nigdy więcej go nie obejrzę' możemy stwierdzić, że wypowiedź ta ma <mask> charakter\",\n",
    "    \"Analizując emocje w tekście 'Ten film zupełnie mi się nie podobał. Był tragiczny.' możemy stwierdzić, że wypowiedź ta ma <mask> charakter\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:42.385183200Z",
     "start_time": "2024-11-06T10:07:42.321234500Z"
    }
   },
   "id": "5698c347f379ed3"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pozytywny\n",
      "pozytywny\n",
      "pozytywny\n",
      "pozytywny\n",
      "pozytywny\n"
     ]
    }
   ],
   "source": [
    "for query, case in zip(queries_roberta, cases):\n",
    "    print(roberta(query)[0][\"token_str\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:42.684824900Z",
     "start_time": "2024-11-06T10:07:42.323184400Z"
    }
   },
   "id": "ae6fae2e72fc46c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zero-shot learning returns many false positives"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b714d868f6e32a8"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pozytywny\n",
      "pozytywny\n",
      "pozytywny\n",
      "pozytywny\n",
      "pozytywny\n"
     ]
    }
   ],
   "source": [
    "for query, case in zip(queries_roberta, cases):\n",
    "    print(roberta(query)[0][\"token_str\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:42.952481900Z",
     "start_time": "2024-11-06T10:07:42.623823300Z"
    }
   },
   "id": "a8bc203f1027af55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Same as above"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c761c4a33d472cc4"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "돔\n",
      "돔\n",
      "돔\n",
      "돔\n",
      "돔\n"
     ]
    }
   ],
   "source": [
    "queries_distilbert = [q.replace(\"<mask>\", \"[MASK]\") for q in queries_roberta]\n",
    "\n",
    "for query, case in zip(queries_distilbert, cases):\n",
    "    print(distilbert(query)[0][\"token_str\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-06T10:07:43.166848800Z",
     "start_time": "2024-11-06T10:07:42.942480500Z"
    }
   },
   "id": "6889007f6a4c6a06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "What is this even..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "719d3d85e0368e0b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 7 and 8"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1206f224ce9d9c86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Answer the following questions:\n",
    "   1. Which of the models produced the best results? - Polish longformer model. Other models were trained as general multi-lingual model. It's safe to assume that Polish longformer was fine-tuned for the Polish language.\n",
    "   1. Was any of the models able to capture Polish grammar? - Roberta and longformer performed well but only longformer didn't make any mistake.\n",
    "   1. Was any of the models able to capture long-distant relationships between the words? - Roberta and longformer captured the long-distance relationship correctly.\n",
    "   1. Was any of the models able to capture world knowledge? - Only the model specific to Polish language was able to capture world knowledge. Roberta model was able to solve the task in english.\n",
    "   1. Was any of the models good at doing zero-shot classification? - None of them wre \n",
    "   1. What are the most striking errors made by the models? - The errors returned in world knowledge tasks. Roberta confused \"first month of the year\" with \"first day of the week\". Distilbert replied with \"year\" even though the world \"year\" is used in the sentence."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52109fd30865385c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9470aaca997d7392"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
